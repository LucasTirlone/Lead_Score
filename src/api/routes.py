# Copyright (c) Microsoft. All rights reserved.
# Licensed under the MIT license.
# See LICENSE file in the project root for full license information.

# ─────────────────────────────── imports ──────────────────────────────────
import json
import logging
import os
import secrets
from typing import Dict, Optional


import fastapi
from fastapi import Depends, HTTPException, Request, status
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse
from fastapi.security import HTTPBasic, HTTPBasicCredentials
from fastapi.templating import Jinja2Templates

from azure.ai.inference.aio import ChatCompletionsClient
from azure.ai.inference.prompts import PromptTemplate           # usado pelo /chat (stream)
from azure.core.exceptions import HttpResponseError

from .util import get_logger, ChatRequest                       # logger + modelos Pydantic
from .search_index_manager import SearchIndexManager            # usado pelo /chat (stream)
from .normalize_leads import normalize_batch                    # seu normalizador

# ─────────────────────────── system prompt ────────────────────────────────
NOTEEFY_PROMPT = r"""
You are “Noteefy-AI-Lead-Scorer”, an expert assistant that assigns qualitative lead-scores for golf-resort booking requests.

────────────────────────────────────────────────────────────────────────────
Core business context
────────────────────────────────────────────────────────────────────────────
• The resort sells tee-times and on-property lodging (cottages, lodge rooms, suites, etc.).  
• Admins seed you with two static JSON files (loaded from knowledge-base):  
  1. pricing_seed.json → nightly price per lodging type.  
  2. fixed_presets.json → boolean flags that turn individual scoring rules ON/OFF.  
• The end-user uploads only the leads: an array of raw form submissions (schema varies per customer).

────────────────────────────────────────────────────────────────────────────
Dynamic input mapping  (✓ schema-agnostic)
────────────────────────────────────────────────────────────────────────────
Always extract these fields from each submission **at runtime**, matching partial keys:

| Canonical field                  | Match if key CONTAINS …                                   |
|----------------------------------|-----------------------------------------------------------|
| group_size                       | “group size”, “size”                                      |
| preferred_lodging_type (list)    | “lodging option”, “lodging”                               |
| desired_date_ranges (list)       | “SelectedDateRanges”; or pairs of “Start Date” / “End Date”|
| notes / free text                | “comment”, “instruction”, “note”                         |
| text_opt_in (bool)               | “text update request”, “sms”                             |
| email_opt_in (bool)              | “email update request”                                   |
| phone_present (bool)             | “phone”, “cell phone”, “mobile”                          |

If any field is missing, fall back gracefully (e.g., group_size → 1, lodging → ["Any"]).

────────────────────────────────────────────────────────────────────────────
Output contract  (always return **valid JSON**)
────────────────────────────────────────────────────────────────────────────
{
  "run_id": "<ulid or UTC timestamp>",
  "active_lead_score_name": "<auto-generated concise title>",
  "overview": {
    "Very High": <int>, "High": <int>,
    "Medium": <int>, "Low": <int>, "Very Low": <int>
  },
  "scored_leads": [
    {
      "submission_id": "<original _id string>",
      "rating": "Very High|High|Medium|Low|Very Low",
      "score": <int 0-100>,
      "estimated_revenue": <float>,         // nights × price_per_night × group_size
      "reason": "<≤200 chars, no PII>",
      "conflict_warnings": [ "<text ≤400 chars>", … ]   // optional, per-lead
    }
  ],
  "conflict_warnings": [ "<text ≤400 chars>", … ]        // optional, global
}

────────────────────────────────────────────────────────────────────────────
Scoring buckets  (use **exact** labels)
────────────────────────────────────────────────────────────────────────────
Very High   – fully matches every active criterion and is strongly price-efficient  
High        – nearly perfect; at most one soft miss  
Medium      – some relevant overlap but not compelling  
Low         – little overlap or soft conflicts  
Very Low    – strongly misaligned; follow-up not worthwhile now  

────────────────────────────────────────────────────────────────────────────
Scoring mechanics  (strict order, applied per lead)
────────────────────────────────────────────────────────────────────────────
1. Extract canonical fields via the dynamic mapping rules above.  
2. Treat all dates/units as available (no availability_feed).  
3. **Price-fit** – compare preferred_lodging_type against pricing_seed; choose the cheapest compatible nightly rate.  
4. **Estimated revenue** = (# nights in widest requested range) × price_per_night × group_size.  
5. Apply preset rules that are *true* in fixed_presets.json:  
   • prioritize_large_groups             → boost group_size ≥ 4.  
   • boost_lodging_match_exact           → boost if lodging name matches exactly a key in pricing_seed.  
   • reward_date_flexibility             → higher score when multiple ranges or gaps ≥ 3 days.  
   • prefer_text_opt_in                  → boost if text_opt_in == true.  
   • boost_repeat_guest_note_match       → boost if notes contain return-guest wording.  
   • penalize_missing_phone              → **deduct** if phone_present == false (mandatory when flag is true).  
6. Combine all factors into a numeric **score 0-100**, then map to rating bucket.  
7. Build the “reason” (≤ 200 chars, no PII).  
8. Detect inconsistencies (e.g., lodging label not in pricing_seed) → add to per-lead conflict_warnings.  
9. **Never halt processing**; even with warnings, continue through every submission.

────────────────────────────────────────────────────────────────────────────
Simulation mode
────────────────────────────────────────────────────────────────────────────
If the user sets `"simulate_only": true`, ignore real leads and output **exactly five** placeholder
records with names: Olivia Prescott, Frank Smith, Ryan Thatcher, Tomas Martinez, Noah Harrington.
Spread ratings evenly from Very High → Very Low with realistic scores/reasons.

────────────────────────────────────────────────────────────────────────────
Absolutely important
────────────────────────────────────────────────────────────────────────────
• Respond **only** with the JSON object; never add plain text.  
• Never include emails, phone numbers, postal codes or other PII.  
• Never invent new rating labels.  
• Never return incomplete or empty objects in "scored_leads".  
• “reason” must be natural-language, ≤ 200 chars, no emojis or logs.  
• Each score must be numeric 0-100.  
• All JSON must be syntactically valid (escaped strings, commas, brackets).  
• Process every lead; do not abort due to non-fatal warnings.

────────────────────────────────────────────────────────────────────────────

"""
# ──────────────────────── configuração de auth básica ─────────────────────
security      = HTTPBasic()
username      = os.getenv("WEB_APP_USERNAME")
password      = os.getenv("WEB_APP_PASSWORD")
basic_auth_on = username and password

def authenticate(creds: Optional[HTTPBasicCredentials] = Depends(security)) -> None:
    """HTTP Basic auth (opcional)."""
    if not basic_auth_on:
        logger.info("Skipping authentication: credentials not set.")
        return

    ok_user = secrets.compare_digest(creds.username, username)
    ok_pass = secrets.compare_digest(creds.password, password)
    if not (ok_user and ok_pass):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid credentials",
            headers={"WWW-Authenticate": "Basic"},
        )

auth_dep = Depends(authenticate) if basic_auth_on else None

# ───────────────────────────── logger / router ────────────────────────────
logger     = get_logger("azureaiapp_routes", logging.INFO, os.getenv("APP_LOG_FILE"), True)
router     = fastapi.APIRouter()
templates  = Jinja2Templates(directory="api/templates")

# ───────────────────────── helpers para app.state ─────────────────────────
def get_chat_client(request: Request) -> ChatCompletionsClient:
    return request.app.state.chat

def get_chat_model(request: Request) -> str:
    return request.app.state.chat_model

def get_search_index_manager(request: Request) -> SearchIndexManager:
    return request.app.state.search_index_manager

def serialize_sse_event(data: Dict) -> str:
    return f"data: {json.dumps(data)}\n\n"

# ───────────────────────── página inicial (UI demo) ───────────────────────
@router.get("/", response_class=HTMLResponse)
async def index_name(request: Request, _ = auth_dep):
    return templates.TemplateResponse("index.html", {"request": request})

# ─────────────────────────── endpoint original /chat (stream) ─────────────
@router.post("/chat")
async def chat_stream_handler(
    chat_request: ChatRequest,
    chat_client: ChatCompletionsClient          = Depends(get_chat_client),
    model_deployment_name: str                 = Depends(get_chat_model),
    search_index_manager: SearchIndexManager   = Depends(get_search_index_manager),
    _ = auth_dep
) -> StreamingResponse:
    """
    Endpoint de exemplo que usa SSE + RAG (mantido do template original).
    """
    headers = {
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "Content-Type": "text/event-stream"
    }

    if chat_client is None:
        raise Exception("Chat client not initialized")

    async def response_stream():
        messages = [{"role": m.role, "content": m.content} for m in chat_request.messages]

        prompt_messages = PromptTemplate.from_string('You are a helpful assistant').create_messages()
        # RAG opcional usando search_index_manager
        if search_index_manager is not None:
            context = await search_index_manager.search(chat_request)
            if context:
                prompt_messages = PromptTemplate.from_string(
                    'You are a helpful assistant that answers some questions '
                    'with the help of some context data.\n\nHere is the context data:\n\n{{context}}'
                ).create_messages(data=dict(context=context))
                logger.info(f"{prompt_messages=}")

        try:
            accumulated = ""
            stream = await chat_client.complete(
                model=model_deployment_name,
                messages=prompt_messages + messages,
                stream=True
            )
            async for event in stream:
                if event.choices:
                    delta = event.choices[0].delta.content
                    if delta:
                        accumulated += delta
                        yield serialize_sse_event({"type": "message", "content": delta})

            yield serialize_sse_event({"type": "completed_message", "content": accumulated})
        except BaseException as e:
            logger.error(str(e))
            yield serialize_sse_event({"type": "completed_message", "content": str(e)})
        yield serialize_sse_event({"type": "stream_end"})

    return StreamingResponse(response_stream(), headers=headers)

# ─────────────────────────── novo endpoint /lead-score ────────────────────
@router.post("/lead-score")
async def lead_score_handler(
    request: Request,
    chat_client: ChatCompletionsClient = Depends(get_chat_client),
    model_deployment_name: str          = Depends(get_chat_model),
    _ = auth_dep
):
    """
    Recebe {"leads":[...]} → normaliza → chama o modelo → devolve JSON de scoring.
    """
    if chat_client is None:
        raise HTTPException(500, "Chat client not initialized")

    raw_payload     = await request.json()
    cleaned_payload = normalize_batch(raw_payload)          # ← normalização dinâmica

    messages = [
        {"role": "system", "content": NOTEEFY_PROMPT},
        {"role": "user",   "content": json.dumps(cleaned_payload)}
    ]

    try:
        completion = await chat_client.complete(
            model      = model_deployment_name,
            messages   = messages,
            temperature= 0
        )
        content = completion.choices[0].message.content
        return JSONResponse(status_code=200, content=json.loads(content))
    except HttpResponseError as e:
        logger.error(f"Model call failed: {e}")
        raise HTTPException(500, str(e))
